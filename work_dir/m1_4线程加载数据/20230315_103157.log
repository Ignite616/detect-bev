2023-03-15 10:31:57,455 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA T1200 Laptop GPU
CUDA_HOME: /usr/local/cuda-11.6
NVCC: Build cuda_11.6.r11.6/compiler.30794723_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.9.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.10.0
OpenCV: 4.6.0
MMCV: 1.4.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 10.2
MMDetection: 2.14.0
MMSegmentation: 0.14.1
MMDetection3D: 0.16.0+
------------------------------------------------------------

2023-03-15 10:31:58,368 - mmdet - INFO - Distributed training: False
2023-03-15 10:31:59,257 - mmdet - INFO - Config:
model = dict(
    type='FastBEV',
    style='v1',
    backbone=dict(
        type='ResNet',
        depth=18,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet18'),
        style='pytorch'),
    neck=dict(
        type='FPN',
        norm_cfg=dict(type='BN', requires_grad=True),
        in_channels=[64, 128, 256, 512],
        out_channels=64,
        num_outs=4),
    neck_fuse=dict(in_channels=[256], out_channels=[64]),
    neck_3d=dict(
        type='M2BevNeck',
        in_channels=256,
        out_channels=192,
        num_layers=2,
        stride=2,
        is_transpose=False,
        fuse=dict(in_channels=1024, out_channels=256),
        norm_cfg=dict(type='BN', requires_grad=True)),
    seg_head=None,
    bbox_head=dict(
        type='FreeAnchor3DHead',
        is_transpose=True,
        num_classes=10,
        in_channels=192,
        feat_channels=192,
        num_convs=0,
        use_direction_classifier=True,
        pre_anchor_topk=25,
        bbox_thr=0.5,
        gamma=2.0,
        alpha=0.5,
        anchor_generator=dict(
            type='AlignedAnchor3DRangeGenerator',
            ranges=[[-50, -50, -1.8, 50, 50, -1.8]],
            sizes=[[0.866, 2.5981, 1.0], [0.5774, 1.7321, 1.0],
                   [1.0, 1.0, 1.0], [0.4, 0.4, 1]],
            custom_values=[0, 0],
            rotations=[0, 1.57],
            reshape_out=True),
        assigner_per_size=False,
        diff_rad_by_sin=True,
        dir_offset=0.7854,
        dir_limit_offset=0,
        bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder', code_size=9),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0),
        loss_bbox=dict(
            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=0.8),
        loss_dir=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.8)),
    multi_scale_id=[0],
    n_voxels=[[200, 200, 4]],
    voxel_size=[[0.5, 0.5, 1.5]],
    train_cfg=dict(
        assigner=dict(
            type='MaxIoUAssigner',
            iou_calculator=dict(type='BboxOverlapsNearest3D'),
            pos_iou_thr=0.6,
            neg_iou_thr=0.3,
            min_pos_iou=0.3,
            ignore_iof_thr=-1),
        allowed_border=0,
        code_weight=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
        pos_weight=-1,
        debug=False),
    test_cfg=dict(
        score_thr=0.05,
        min_bbox_size=0,
        nms_pre=1000,
        max_num=500,
        use_scale_nms=True,
        use_tta=False,
        nms_across_levels=False,
        use_rotate_nms=True,
        nms_thr=0.2,
        nms_type_list=[
            'rotate', 'rotate', 'rotate', 'rotate', 'rotate', 'rotate',
            'rotate', 'rotate', 'rotate', 'circle'
        ],
        nms_thr_list=[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.5, 0.5, 0.2],
        nms_radius_thr_list=[4, 12, 10, 10, 12, 0.85, 0.85, 0.175, 0.175, 1],
        nms_rescale_factor=[1.0, 0.7, 0.55, 0.4, 0.7, 1.0, 1.0, 4.5, 9.0,
                            1.0]))
point_cloud_range = [-50, -50, -5, 50, 50, 3]
class_names = [
    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',
    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
]
dataset_type = 'NuScenesMultiView_Map_Dataset2'
data_root = './data/nuscenes/'
input_modality = dict(
    use_lidar=False,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=True)
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
data_config = dict(
    src_size=(900, 1600),
    input_size=(320, 880),
    resize=(-0.06, 0.11),
    crop=(-0.05, 0.05),
    rot=(-5.4, 5.4),
    flip=True,
    test_input_size=(320, 880),
    test_resize=0.0,
    test_rotate=0.0,
    test_flip=False,
    pad=(0, 0, 0, 0),
    pad_divisor=32,
    pad_color=(0, 0, 0))
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(
        type='MultiViewPipeline',
        sequential=True,
        n_images=6,
        n_times=4,
        transforms=[
            dict(
                type='LoadImageFromFile',
                file_client_args=dict(backend='disk'))
        ]),
    dict(
        type='LoadAnnotations3D',
        with_bbox=True,
        with_label=True,
        with_bev_seg=True),
    dict(
        type='LoadPointsFromFile',
        dummy=True,
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5),
    dict(
        type='RandomFlip3D',
        flip_2d=False,
        sync_2d=False,
        flip_ratio_bev_horizontal=0.5,
        flip_ratio_bev_vertical=0.5,
        update_img2lidar=True),
    dict(
        type='GlobalRotScaleTrans',
        rot_range=[-0.3925, 0.3925],
        scale_ratio_range=[0.95, 1.05],
        translation_std=[0.05, 0.05, 0.05],
        update_img2lidar=True),
    dict(
        type='RandomAugImageMultiViewImage',
        data_config=dict(
            src_size=(900, 1600),
            input_size=(320, 880),
            resize=(-0.06, 0.11),
            crop=(-0.05, 0.05),
            rot=(-5.4, 5.4),
            flip=True,
            test_input_size=(320, 880),
            test_resize=0.0,
            test_rotate=0.0,
            test_flip=False,
            pad=(0, 0, 0, 0),
            pad_divisor=32,
            pad_color=(0, 0, 0))),
    dict(
        type='ObjectRangeFilter', point_cloud_range=[-50, -50, -5, 50, 50, 3]),
    dict(type='KittiSetOrigin', point_cloud_range=[-50, -50, -5, 50, 50, 3]),
    dict(
        type='NormalizeMultiviewImage',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ]),
    dict(
        type='Collect3D',
        keys=[
            'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d',
            'gt_bev_seg'
        ])
]
test_pipeline = [
    dict(
        type='MultiViewPipeline',
        sequential=True,
        n_images=6,
        n_times=4,
        transforms=[
            dict(
                type='LoadImageFromFile',
                file_client_args=dict(backend='disk'))
        ]),
    dict(
        type='LoadPointsFromFile',
        dummy=True,
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5),
    dict(
        type='RandomAugImageMultiViewImage',
        data_config=dict(
            src_size=(900, 1600),
            input_size=(320, 880),
            resize=(-0.06, 0.11),
            crop=(-0.05, 0.05),
            rot=(-5.4, 5.4),
            flip=True,
            test_input_size=(320, 880),
            test_resize=0.0,
            test_rotate=0.0,
            test_flip=False,
            pad=(0, 0, 0, 0),
            pad_divisor=32,
            pad_color=(0, 0, 0)),
        is_train=False),
    dict(type='KittiSetOrigin', point_cloud_range=[-50, -50, -5, 50, 50, 3]),
    dict(
        type='NormalizeMultiviewImage',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['img'])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=4,
    train=dict(
        type='CBGSDataset',
        dataset=dict(
            type='NuScenesMultiView_Map_Dataset2',
            data_root='./data/nuscenes/',
            pipeline=[
                dict(
                    type='MultiViewPipeline',
                    sequential=True,
                    n_images=6,
                    n_times=4,
                    transforms=[
                        dict(
                            type='LoadImageFromFile',
                            file_client_args=dict(backend='disk'))
                    ]),
                dict(
                    type='LoadAnnotations3D',
                    with_bbox=True,
                    with_label=True,
                    with_bev_seg=True),
                dict(
                    type='LoadPointsFromFile',
                    dummy=True,
                    coord_type='LIDAR',
                    load_dim=5,
                    use_dim=5),
                dict(
                    type='RandomFlip3D',
                    flip_2d=False,
                    sync_2d=False,
                    flip_ratio_bev_horizontal=0.5,
                    flip_ratio_bev_vertical=0.5,
                    update_img2lidar=True),
                dict(
                    type='GlobalRotScaleTrans',
                    rot_range=[-0.3925, 0.3925],
                    scale_ratio_range=[0.95, 1.05],
                    translation_std=[0.05, 0.05, 0.05],
                    update_img2lidar=True),
                dict(
                    type='RandomAugImageMultiViewImage',
                    data_config=dict(
                        src_size=(900, 1600),
                        input_size=(320, 880),
                        resize=(-0.06, 0.11),
                        crop=(-0.05, 0.05),
                        rot=(-5.4, 5.4),
                        flip=True,
                        test_input_size=(320, 880),
                        test_resize=0.0,
                        test_rotate=0.0,
                        test_flip=False,
                        pad=(0, 0, 0, 0),
                        pad_divisor=32,
                        pad_color=(0, 0, 0))),
                dict(
                    type='ObjectRangeFilter',
                    point_cloud_range=[-50, -50, -5, 50, 50, 3]),
                dict(
                    type='KittiSetOrigin',
                    point_cloud_range=[-50, -50, -5, 50, 50, 3]),
                dict(
                    type='NormalizeMultiviewImage',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(
                    type='DefaultFormatBundle3D',
                    class_names=[
                        'car', 'truck', 'trailer', 'bus',
                        'construction_vehicle', 'bicycle', 'motorcycle',
                        'pedestrian', 'traffic_cone', 'barrier'
                    ]),
                dict(
                    type='Collect3D',
                    keys=[
                        'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d',
                        'gt_labels_3d', 'gt_bev_seg'
                    ])
            ],
            classes=[
                'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                'barrier'
            ],
            modality=dict(
                use_lidar=False,
                use_camera=True,
                use_radar=False,
                use_map=False,
                use_external=True),
            test_mode=False,
            with_box2d=True,
            box_type_3d='LiDAR',
            ann_file=
            'data/nuscenes/nuscenes_infos_train_4d_interval3_max60.pkl',
            load_interval=1,
            sequential=True,
            n_times=4,
            train_adj_ids=[1, 3, 5],
            speed_mode='abs_velo',
            max_interval=10,
            min_interval=0,
            fix_direction=True,
            prev_only=True,
            test_adj='prev',
            test_adj_ids=[1, 3, 5],
            test_time_id=None)),
    val=dict(
        type='NuScenesMultiView_Map_Dataset2',
        data_root='./data/nuscenes/',
        pipeline=[
            dict(
                type='MultiViewPipeline',
                sequential=True,
                n_images=6,
                n_times=4,
                transforms=[
                    dict(
                        type='LoadImageFromFile',
                        file_client_args=dict(backend='disk'))
                ]),
            dict(
                type='LoadPointsFromFile',
                dummy=True,
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5),
            dict(
                type='RandomAugImageMultiViewImage',
                data_config=dict(
                    src_size=(900, 1600),
                    input_size=(320, 880),
                    resize=(-0.06, 0.11),
                    crop=(-0.05, 0.05),
                    rot=(-5.4, 5.4),
                    flip=True,
                    test_input_size=(320, 880),
                    test_resize=0.0,
                    test_rotate=0.0,
                    test_flip=False,
                    pad=(0, 0, 0, 0),
                    pad_divisor=32,
                    pad_color=(0, 0, 0)),
                is_train=False),
            dict(
                type='KittiSetOrigin',
                point_cloud_range=[-50, -50, -5, 50, 50, 3]),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                    'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                    'barrier'
                ],
                with_label=False),
            dict(type='Collect3D', keys=['img'])
        ],
        classes=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        with_box2d=True,
        box_type_3d='LiDAR',
        ann_file='data/nuscenes/nuscenes_infos_val_4d_interval3_max60.pkl',
        load_interval=1,
        sequential=True,
        n_times=4,
        train_adj_ids=[1, 3, 5],
        speed_mode='abs_velo',
        max_interval=10,
        min_interval=0,
        fix_direction=True,
        test_adj='prev',
        test_adj_ids=[1, 3, 5],
        test_time_id=None),
    test=dict(
        type='NuScenesMultiView_Map_Dataset2',
        data_root='./data/nuscenes/',
        pipeline=[
            dict(
                type='MultiViewPipeline',
                sequential=True,
                n_images=6,
                n_times=4,
                transforms=[
                    dict(
                        type='LoadImageFromFile',
                        file_client_args=dict(backend='disk'))
                ]),
            dict(
                type='LoadPointsFromFile',
                dummy=True,
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5),
            dict(
                type='RandomAugImageMultiViewImage',
                data_config=dict(
                    src_size=(900, 1600),
                    input_size=(320, 880),
                    resize=(-0.06, 0.11),
                    crop=(-0.05, 0.05),
                    rot=(-5.4, 5.4),
                    flip=True,
                    test_input_size=(320, 880),
                    test_resize=0.0,
                    test_rotate=0.0,
                    test_flip=False,
                    pad=(0, 0, 0, 0),
                    pad_divisor=32,
                    pad_color=(0, 0, 0)),
                is_train=False),
            dict(
                type='KittiSetOrigin',
                point_cloud_range=[-50, -50, -5, 50, 50, 3]),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                    'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
                    'barrier'
                ],
                with_label=False),
            dict(type='Collect3D', keys=['img'])
        ],
        classes=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        with_box2d=True,
        box_type_3d='LiDAR',
        ann_file='data/nuscenes/nuscenes_infos_val_4d_interval3_max60.pkl',
        load_interval=1,
        sequential=True,
        n_times=4,
        train_adj_ids=[1, 3, 5],
        speed_mode='abs_velo',
        max_interval=10,
        min_interval=0,
        fix_direction=True,
        test_adj='prev',
        test_adj_ids=[1, 3, 5],
        test_time_id=None))
optimizer = dict(
    type='AdamW2',
    lr=0.0004,
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(backbone=dict(lr_mult=0.1, decay_mult=1.0))))
optimizer_config = dict(grad_clip=dict(max_norm=35.0, norm_type=2))
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1000,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0,
    by_epoch=False)
total_epochs = 20
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=10,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
evaluation = dict(interval=5)
dist_params = dict(backend='nccl')
find_unused_parameters = True
log_level = 'INFO'
load_from = 'cascade_mask_rcnn_r18_fpn_coco-mstrain_3x_20e_nuim_bbox_mAP_0.5110_segm_mAP_0.4070.pth'
resume_from = None
workflow = [('train', 1)]
fp16 = dict(loss_scale='dynamic')
work_dir = 'work_dir'
gpu_ids = range(0, 1)

2023-03-15 10:31:59,257 - mmdet - INFO - Set random seed to 0, deterministic: False
2023-03-15 10:31:59,352 - mmdet - INFO - Model:
FastBEV(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet18'}
  (neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): ConvModule(
        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (neck_3d): M2BevNeck(
    (fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (model): Sequential(
      (0): ResModule2D(
        (conv0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (conv1): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (activation): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(256, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (2): ResModule2D(
        (conv0): ConvModule(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (conv1): ConvModule(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (activation): ReLU(inplace=True)
      )
      (3): ConvModule(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (4): ResModule2D(
        (conv0): ConvModule(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (conv1): ConvModule(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (activation): ReLU(inplace=True)
      )
      (5): ConvModule(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (neck_fuse_0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bbox_head): FreeAnchor3DHead(
    (loss_cls): FocalLoss()
    (loss_bbox): SmoothL1Loss()
    (loss_dir): CrossEntropyLoss()
    (convs): Identity()
    (conv_cls): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))
    (conv_reg): Conv2d(192, 72, kernel_size=(1, 1), stride=(1, 1))
    (conv_dir_cls): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'conv_cls', 'std': 0.01, 'bias_prob': 0.01}}
)
2023-03-15 10:32:03,738 - mmdet - INFO - load checkpoint from local path: cascade_mask_rcnn_r18_fpn_coco-mstrain_3x_20e_nuim_bbox_mAP_0.5110_segm_mAP_0.4070.pth
2023-03-15 10:32:04,086 - mmdet - WARNING - The model and loaded state dict do not match exactly

size mismatch for neck.lateral_convs.0.conv.weight: copying a param with shape torch.Size([256, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).
size mismatch for neck.lateral_convs.0.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.0.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.0.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.0.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.1.conv.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).
size mismatch for neck.lateral_convs.1.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.1.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.1.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.1.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.2.conv.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).
size mismatch for neck.lateral_convs.2.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.2.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.2.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.2.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.3.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 512, 1, 1]).
size mismatch for neck.lateral_convs.3.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.3.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.3.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.lateral_convs.3.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.0.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).
size mismatch for neck.fpn_convs.0.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.0.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.0.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.0.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.1.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).
size mismatch for neck.fpn_convs.1.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.1.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.1.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.1.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.2.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).
size mismatch for neck.fpn_convs.2.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.2.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.2.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.2.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.3.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).
size mismatch for neck.fpn_convs.3.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.3.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.3.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for neck.fpn_convs.3.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
unexpected key in source state_dict: rpn_head.rpn_conv.weight, rpn_head.rpn_conv.bias, rpn_head.rpn_cls.weight, rpn_head.rpn_cls.bias, rpn_head.rpn_reg.weight, rpn_head.rpn_reg.bias, roi_head.bbox_head.0.fc_cls.weight, roi_head.bbox_head.0.fc_cls.bias, roi_head.bbox_head.0.fc_reg.weight, roi_head.bbox_head.0.fc_reg.bias, roi_head.bbox_head.0.shared_fcs.0.weight, roi_head.bbox_head.0.shared_fcs.0.bias, roi_head.bbox_head.0.shared_fcs.1.weight, roi_head.bbox_head.0.shared_fcs.1.bias, roi_head.bbox_head.1.fc_cls.weight, roi_head.bbox_head.1.fc_cls.bias, roi_head.bbox_head.1.fc_reg.weight, roi_head.bbox_head.1.fc_reg.bias, roi_head.bbox_head.1.shared_fcs.0.weight, roi_head.bbox_head.1.shared_fcs.0.bias, roi_head.bbox_head.1.shared_fcs.1.weight, roi_head.bbox_head.1.shared_fcs.1.bias, roi_head.bbox_head.2.fc_cls.weight, roi_head.bbox_head.2.fc_cls.bias, roi_head.bbox_head.2.fc_reg.weight, roi_head.bbox_head.2.fc_reg.bias, roi_head.bbox_head.2.shared_fcs.0.weight, roi_head.bbox_head.2.shared_fcs.0.bias, roi_head.bbox_head.2.shared_fcs.1.weight, roi_head.bbox_head.2.shared_fcs.1.bias, roi_head.mask_head.0.convs.0.conv.weight, roi_head.mask_head.0.convs.0.conv.bias, roi_head.mask_head.0.convs.1.conv.weight, roi_head.mask_head.0.convs.1.conv.bias, roi_head.mask_head.0.convs.2.conv.weight, roi_head.mask_head.0.convs.2.conv.bias, roi_head.mask_head.0.convs.3.conv.weight, roi_head.mask_head.0.convs.3.conv.bias, roi_head.mask_head.0.upsample.weight, roi_head.mask_head.0.upsample.bias, roi_head.mask_head.0.conv_logits.weight, roi_head.mask_head.0.conv_logits.bias, roi_head.mask_head.1.convs.0.conv.weight, roi_head.mask_head.1.convs.0.conv.bias, roi_head.mask_head.1.convs.1.conv.weight, roi_head.mask_head.1.convs.1.conv.bias, roi_head.mask_head.1.convs.2.conv.weight, roi_head.mask_head.1.convs.2.conv.bias, roi_head.mask_head.1.convs.3.conv.weight, roi_head.mask_head.1.convs.3.conv.bias, roi_head.mask_head.1.upsample.weight, roi_head.mask_head.1.upsample.bias, roi_head.mask_head.1.conv_logits.weight, roi_head.mask_head.1.conv_logits.bias, roi_head.mask_head.2.convs.0.conv.weight, roi_head.mask_head.2.convs.0.conv.bias, roi_head.mask_head.2.convs.1.conv.weight, roi_head.mask_head.2.convs.1.conv.bias, roi_head.mask_head.2.convs.2.conv.weight, roi_head.mask_head.2.convs.2.conv.bias, roi_head.mask_head.2.convs.3.conv.weight, roi_head.mask_head.2.convs.3.conv.bias, roi_head.mask_head.2.upsample.weight, roi_head.mask_head.2.upsample.bias, roi_head.mask_head.2.conv_logits.weight, roi_head.mask_head.2.conv_logits.bias

missing keys in source state_dict: neck_3d.fuse.weight, neck_3d.fuse.bias, neck_3d.model.0.conv0.conv.weight, neck_3d.model.0.conv0.bn.weight, neck_3d.model.0.conv0.bn.bias, neck_3d.model.0.conv0.bn.running_mean, neck_3d.model.0.conv0.bn.running_var, neck_3d.model.0.conv1.conv.weight, neck_3d.model.0.conv1.bn.weight, neck_3d.model.0.conv1.bn.bias, neck_3d.model.0.conv1.bn.running_mean, neck_3d.model.0.conv1.bn.running_var, neck_3d.model.1.conv.weight, neck_3d.model.1.bn.weight, neck_3d.model.1.bn.bias, neck_3d.model.1.bn.running_mean, neck_3d.model.1.bn.running_var, neck_3d.model.2.conv0.conv.weight, neck_3d.model.2.conv0.bn.weight, neck_3d.model.2.conv0.bn.bias, neck_3d.model.2.conv0.bn.running_mean, neck_3d.model.2.conv0.bn.running_var, neck_3d.model.2.conv1.conv.weight, neck_3d.model.2.conv1.bn.weight, neck_3d.model.2.conv1.bn.bias, neck_3d.model.2.conv1.bn.running_mean, neck_3d.model.2.conv1.bn.running_var, neck_3d.model.3.conv.weight, neck_3d.model.3.bn.weight, neck_3d.model.3.bn.bias, neck_3d.model.3.bn.running_mean, neck_3d.model.3.bn.running_var, neck_3d.model.4.conv0.conv.weight, neck_3d.model.4.conv0.bn.weight, neck_3d.model.4.conv0.bn.bias, neck_3d.model.4.conv0.bn.running_mean, neck_3d.model.4.conv0.bn.running_var, neck_3d.model.4.conv1.conv.weight, neck_3d.model.4.conv1.bn.weight, neck_3d.model.4.conv1.bn.bias, neck_3d.model.4.conv1.bn.running_mean, neck_3d.model.4.conv1.bn.running_var, neck_3d.model.5.conv.weight, neck_3d.model.5.bn.weight, neck_3d.model.5.bn.bias, neck_3d.model.5.bn.running_mean, neck_3d.model.5.bn.running_var, neck_fuse_0.weight, neck_fuse_0.bias, bbox_head.conv_cls.weight, bbox_head.conv_cls.bias, bbox_head.conv_reg.weight, bbox_head.conv_reg.bias, bbox_head.conv_dir_cls.weight, bbox_head.conv_dir_cls.bias

2023-03-15 10:32:04,092 - mmdet - INFO - Start running, host: huofeng@huofeng-p15, work_dir: /home/huofeng/Fast-BEV-dev/work_dir
2023-03-15 10:32:04,092 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2023-03-15 10:32:04,092 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs
2023-03-15 10:32:04,093 - mmdet - INFO - Checkpoints will be saved to /home/huofeng/Fast-BEV-dev/work_dir by HardDiskBackend.
2023-03-15 10:32:25,887 - mmdet - INFO - Epoch [1][10/323]	lr: 3.595e-06, eta: 3:51:31, time: 2.154, data_time: 0.349, memory: 2204, positive_bag_loss: 2.3876, negative_bag_loss: 114.6138, loss: 117.0014, grad_norm: inf
2023-03-15 10:32:37,463 - mmdet - INFO - Epoch [1][20/323]	lr: 7.578e-06, eta: 2:57:42, time: 1.158, data_time: 0.009, memory: 2204, positive_bag_loss: 2.5961, negative_bag_loss: 217.9870, loss: 220.5831, grad_norm: inf
2023-03-15 10:32:49,060 - mmdet - INFO - Epoch [1][30/323]	lr: 1.155e-05, eta: 2:39:42, time: 1.160, data_time: 0.010, memory: 2204, positive_bag_loss: 2.4505, negative_bag_loss: 171.4431, loss: 173.8936, grad_norm: inf
2023-03-15 10:33:00,672 - mmdet - INFO - Epoch [1][40/323]	lr: 1.551e-05, eta: 2:30:39, time: 1.161, data_time: 0.009, memory: 2204, positive_bag_loss: 2.6764, negative_bag_loss: 214.0068, loss: 216.6832, grad_norm: 226.3968
2023-03-15 10:33:12,265 - mmdet - INFO - Epoch [1][50/323]	lr: 1.945e-05, eta: 2:25:06, time: 1.159, data_time: 0.009, memory: 2204, positive_bag_loss: 2.5027, negative_bag_loss: 173.4492, loss: 175.9519, grad_norm: 184.8613
2023-03-15 10:33:23,873 - mmdet - INFO - Epoch [1][60/323]	lr: 2.338e-05, eta: 2:21:22, time: 1.161, data_time: 0.008, memory: 2204, positive_bag_loss: 2.6214, negative_bag_loss: 271.6500, loss: 274.2715, grad_norm: 288.2646
2023-03-15 10:33:35,498 - mmdet - INFO - Epoch [1][70/323]	lr: 2.731e-05, eta: 2:18:40, time: 1.162, data_time: 0.009, memory: 2204, positive_bag_loss: 2.4819, negative_bag_loss: 167.9489, loss: 170.4308, grad_norm: 178.0948
2023-03-15 10:33:47,104 - mmdet - INFO - Epoch [1][80/323]	lr: 3.121e-05, eta: 2:16:34, time: 1.161, data_time: 0.008, memory: 2204, positive_bag_loss: 2.4845, negative_bag_loss: 155.8966, loss: 158.3811, grad_norm: 153.8875
2023-03-15 10:33:58,729 - mmdet - INFO - Epoch [1][90/323]	lr: 3.511e-05, eta: 2:14:55, time: 1.162, data_time: 0.009, memory: 2204, positive_bag_loss: 2.3394, negative_bag_loss: 117.3736, loss: 119.7130, grad_norm: 124.8019
2023-03-15 10:34:10,357 - mmdet - INFO - Epoch [1][100/323]	lr: 3.899e-05, eta: 2:13:34, time: 1.163, data_time: 0.008, memory: 2204, positive_bag_loss: 2.5156, negative_bag_loss: 130.2329, loss: 132.7485, grad_norm: 153.0378
2023-03-15 10:34:22,014 - mmdet - INFO - Epoch [1][110/323]	lr: 4.286e-05, eta: 2:12:26, time: 1.166, data_time: 0.010, memory: 2204, positive_bag_loss: 2.5081, negative_bag_loss: 109.7905, loss: 112.2986, grad_norm: 132.2409
2023-03-15 10:34:33,695 - mmdet - INFO - Epoch [1][120/323]	lr: 4.672e-05, eta: 2:11:30, time: 1.168, data_time: 0.009, memory: 2204, positive_bag_loss: 2.4771, negative_bag_loss: 113.2678, loss: 115.7449, grad_norm: 142.1388
2023-03-15 10:34:45,429 - mmdet - INFO - Epoch [1][130/323]	lr: 5.057e-05, eta: 2:10:43, time: 1.173, data_time: 0.010, memory: 2204, positive_bag_loss: 2.5398, negative_bag_loss: 112.7199, loss: 115.2597, grad_norm: 147.3574
2023-03-15 10:34:57,130 - mmdet - INFO - Epoch [1][140/323]	lr: 5.440e-05, eta: 2:09:59, time: 1.170, data_time: 0.009, memory: 2204, positive_bag_loss: 2.3618, negative_bag_loss: 94.8773, loss: 97.2392, grad_norm: 127.5810
2023-03-15 10:35:08,856 - mmdet - INFO - Epoch [1][150/323]	lr: 5.823e-05, eta: 2:09:21, time: 1.173, data_time: 0.010, memory: 2204, positive_bag_loss: 2.2947, negative_bag_loss: 54.6764, loss: 56.9711, grad_norm: 80.9914
2023-03-15 10:35:20,565 - mmdet - INFO - Epoch [1][160/323]	lr: 6.203e-05, eta: 2:08:45, time: 1.171, data_time: 0.009, memory: 2204, positive_bag_loss: 2.2912, negative_bag_loss: 67.5208, loss: 69.8120, grad_norm: 95.7878
2023-03-15 10:35:32,294 - mmdet - INFO - Epoch [1][170/323]	lr: 6.583e-05, eta: 2:08:13, time: 1.173, data_time: 0.010, memory: 2204, positive_bag_loss: 2.2931, negative_bag_loss: 46.7138, loss: 49.0069, grad_norm: 68.8701
2023-03-15 10:35:44,043 - mmdet - INFO - Epoch [1][180/323]	lr: 6.962e-05, eta: 2:07:44, time: 1.175, data_time: 0.009, memory: 2204, positive_bag_loss: 2.2148, negative_bag_loss: 43.4605, loss: 45.6752, grad_norm: 71.6744
2023-03-15 10:35:55,789 - mmdet - INFO - Epoch [1][190/323]	lr: 7.339e-05, eta: 2:07:17, time: 1.175, data_time: 0.010, memory: 2204, positive_bag_loss: 2.2889, negative_bag_loss: 59.3172, loss: 61.6061, grad_norm: 95.9803
2023-03-15 10:36:07,488 - mmdet - INFO - Epoch [1][200/323]	lr: 7.715e-05, eta: 2:06:50, time: 1.170, data_time: 0.009, memory: 2204, positive_bag_loss: 2.3402, negative_bag_loss: 46.0744, loss: 48.4145, grad_norm: 77.5380
2023-03-15 10:36:19,209 - mmdet - INFO - Epoch [1][210/323]	lr: 8.090e-05, eta: 2:06:25, time: 1.172, data_time: 0.010, memory: 2204, positive_bag_loss: 2.3726, negative_bag_loss: 58.0168, loss: 60.3894, grad_norm: 98.3430
2023-03-15 10:36:30,952 - mmdet - INFO - Epoch [1][220/323]	lr: 8.463e-05, eta: 2:06:01, time: 1.174, data_time: 0.009, memory: 2204, positive_bag_loss: 2.2544, negative_bag_loss: 33.5171, loss: 35.7715, grad_norm: 61.1482
2023-03-15 10:36:42,672 - mmdet - INFO - Epoch [1][230/323]	lr: 8.835e-05, eta: 2:05:38, time: 1.172, data_time: 0.009, memory: 2204, positive_bag_loss: 2.4303, negative_bag_loss: 47.0786, loss: 49.5089, grad_norm: 84.8951
2023-03-15 10:36:54,386 - mmdet - INFO - Epoch [1][240/323]	lr: 9.206e-05, eta: 2:05:16, time: 1.171, data_time: 0.010, memory: 2204, positive_bag_loss: 2.2948, negative_bag_loss: 19.1689, loss: 21.4637, grad_norm: 39.7023
2023-03-15 10:37:06,081 - mmdet - INFO - Epoch [1][250/323]	lr: 9.576e-05, eta: 2:04:54, time: 1.169, data_time: 0.009, memory: 2204, positive_bag_loss: 2.2729, negative_bag_loss: 20.3260, loss: 22.5989, grad_norm: 47.7882
2023-03-15 10:37:17,825 - mmdet - INFO - Epoch [1][260/323]	lr: 9.945e-05, eta: 2:04:35, time: 1.174, data_time: 0.010, memory: 2204, positive_bag_loss: 2.2493, negative_bag_loss: 13.8583, loss: 16.1076, grad_norm: 27.4866
2023-03-15 10:37:29,541 - mmdet - INFO - Epoch [1][270/323]	lr: 1.031e-04, eta: 2:04:15, time: 1.172, data_time: 0.009, memory: 2204, positive_bag_loss: 2.2218, negative_bag_loss: 10.7375, loss: 12.9593, grad_norm: 23.6591
2023-03-15 10:37:41,248 - mmdet - INFO - Epoch [1][280/323]	lr: 1.068e-04, eta: 2:03:55, time: 1.171, data_time: 0.010, memory: 2204, positive_bag_loss: 2.3956, negative_bag_loss: 13.6192, loss: 16.0148, grad_norm: 33.1464
2023-03-15 10:37:52,980 - mmdet - INFO - Epoch [1][290/323]	lr: 1.104e-04, eta: 2:03:37, time: 1.173, data_time: 0.009, memory: 2204, positive_bag_loss: 2.3907, negative_bag_loss: 13.6982, loss: 16.0889, grad_norm: 30.0731
2023-03-15 10:38:04,707 - mmdet - INFO - Epoch [1][300/323]	lr: 1.141e-04, eta: 2:03:19, time: 1.173, data_time: 0.010, memory: 2204, positive_bag_loss: 2.3324, negative_bag_loss: 8.6893, loss: 11.0217, grad_norm: 21.3383
2023-03-15 10:38:16,474 - mmdet - INFO - Epoch [1][310/323]	lr: 1.177e-04, eta: 2:03:02, time: 1.177, data_time: 0.010, memory: 2204, positive_bag_loss: 2.4108, negative_bag_loss: 7.7423, loss: 10.1531, grad_norm: 20.3897
2023-03-15 10:38:28,192 - mmdet - INFO - Epoch [1][320/323]	lr: 1.213e-04, eta: 2:02:44, time: 1.172, data_time: 0.010, memory: 2204, positive_bag_loss: 2.4732, negative_bag_loss: 9.5593, loss: 12.0325, grad_norm: 25.0262
2023-03-15 10:38:31,755 - mmdet - INFO - Saving checkpoint at 1 epochs
2023-03-15 10:38:47,159 - mmdet - INFO - Epoch [2][10/323]	lr: 1.260e-04, eta: 2:02:21, time: 1.516, data_time: 0.351, memory: 2204, positive_bag_loss: 2.4460, negative_bag_loss: 4.9724, loss: 7.4185, grad_norm: 13.4822
2023-03-15 10:38:58,870 - mmdet - INFO - Epoch [2][20/323]	lr: 1.296e-04, eta: 2:02:04, time: 1.171, data_time: 0.008, memory: 2204, positive_bag_loss: 2.4576, negative_bag_loss: 3.6182, loss: 6.0758, grad_norm: 9.8067
2023-03-15 10:39:10,601 - mmdet - INFO - Epoch [2][30/323]	lr: 1.331e-04, eta: 2:01:48, time: 1.173, data_time: 0.009, memory: 2204, positive_bag_loss: 2.5581, negative_bag_loss: 5.0787, loss: 7.6369, grad_norm: 15.7198
2023-03-15 10:39:22,303 - mmdet - INFO - Epoch [2][40/323]	lr: 1.367e-04, eta: 2:01:32, time: 1.170, data_time: 0.009, memory: 2204, positive_bag_loss: 2.6180, negative_bag_loss: 5.0672, loss: 7.6851, grad_norm: 15.3636
2023-03-15 10:39:34,016 - mmdet - INFO - Epoch [2][50/323]	lr: 1.402e-04, eta: 2:01:16, time: 1.171, data_time: 0.009, memory: 2204, positive_bag_loss: 2.4834, negative_bag_loss: 3.7318, loss: 6.2151, grad_norm: 11.5083
2023-03-15 10:39:45,766 - mmdet - INFO - Epoch [2][60/323]	lr: 1.438e-04, eta: 2:01:00, time: 1.175, data_time: 0.009, memory: 2204, positive_bag_loss: 2.5684, negative_bag_loss: 3.1780, loss: 5.7464, grad_norm: 9.9766
2023-03-15 10:39:57,521 - mmdet - INFO - Epoch [2][70/323]	lr: 1.473e-04, eta: 2:00:45, time: 1.175, data_time: 0.009, memory: 2204, positive_bag_loss: 2.5699, negative_bag_loss: 2.7917, loss: 5.3617, grad_norm: 8.0725
2023-03-15 10:40:09,255 - mmdet - INFO - Epoch [2][80/323]	lr: 1.508e-04, eta: 2:00:30, time: 1.173, data_time: 0.010, memory: 2204, positive_bag_loss: 2.5676, negative_bag_loss: 2.8590, loss: 5.4266, grad_norm: 8.5527
